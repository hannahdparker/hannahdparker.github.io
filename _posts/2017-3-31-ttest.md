---
layout: post
title: "Comparing Means With the T-Test"
date: 2017-3-31 00:00:00
excerpt_separator: <!--more-->
---

In this tutorial, I'm going to go over some basic hypothesis testing
with the t-test. The t-test compares population means against each other
to see if there is any statistically significant difference between the
means. Although basic, the t-test can be useful for a quick, initial
analysis.

<!--more-->

### The Data ###


The data we'll be using in this tutorial are the individual game scores
for the 2010-11 season for Derrick Rose and LeBron James. This was
Rose's MVP season, although many viewed James as more deserving of the
award. We'll use basketball-reference's game scores to see if there was
a significant difference between Rose and James' performance during the
season (at least by this metric).

First we're going to bring up the libraries we'll need. We're going to
be using dplyr for data manipulation and prep and ggplot2 for graphing.

```r
library(dplyr)
library(ggplot2)
```

Next, let's gather the data. I put Rose's info in a dataframe called
Rose and James' in a dataframe called James. The Player column is their
last name and the GmSc column is the game scores they had for the
2010-11 season.
```r
rose<- data.frame(Player= "Rose", GmSc=c(14, 26.4, 14.7, 22.2, 9.7, 8, 
23.2, 19.7, 27.6, 19, 14.9, 21.5, 20.7, 24.5, 6, 12.6, 26.3, 7.9, 21.4, 
19.3, 20.7, 13.8, 7.3, 26.4, 26.2, 15.6, 16.1, 14.9, 18.1, 16.7, 21.4, 
17.2, 9.1, 22, 24.4, 25.9, 9.9, 23.2, 26.8, 22.1, 20.2, 16.6, 18.9, 18.5,
17.9, 16.5, 30.9, 5, 22, 21, 16.9, 13.6, 36.4, 23.9, 13.3, 9.9, 19.4,
4.2, 13.8, 16.7, 19, 20.8, 23.7, 16.2, 17, 13.5, 24, 16.1, 28, 14.4, 
32.5, 16.6, 22.8, 23.1, 32.6, 12.9, 27.7, 6.7, 31.6, 15.9, 8.6))

james<- data.frame(Player= "James", GmSc=c(16, 9.6, 10, 15.6, 23.7, 20.6, 
19.4, 22.8, 29, 17.6, 20.6, 20.6, 21.7, 15.5, 17, 18, 11.7, 19.8, 12, 33.7, 
19.7, 12.5, 28.6, 21.7, 19, 11.1, 14.5, 27, 24.4, 11.2, 26.8, 33.3, 12.9,
17.6, 23.1, 28.8, 24, 20.1, 35.1, 17.4, 20.5, 30.1, 15, 34, 25.6, 22.8, 
46.7, 17.2, 5.3, 39.3, 16.9, 14.5, 20.3, 17.7, 17.9, 25.5, 27, 19.7, 26.2, 
20.2, 24, 26.5, 17.8, 23.8, 16.5, 12.7, 32.2, 20.5, 14.9, 28.2, 28.6, 21.9, 
34.6, 26.1, 26.6, 22, 24.7, 23.2, 26.4))
```
### One Sample T-Test ###


Let's first look at Rose by himself. Let's say that out of the entire
population of basketball players, the average game score is 12 (just a
complete guess). I want to know whether Rose's mean game score is
significantly better than the population mean, and not just a result of
random variation. To do this, we can do a one-sample t-test. Using R we
call the t.test function, like so:
```r
t.test(rose$GmSc, mu=12, alternative = "greater")

## 
##  One Sample t-test
## 
## data:  rose$GmSc
## t = 8.8151, df = 80, p-value = 1.014e-13
## alternative hypothesis: true mean is greater than 12
## 95 percent confidence interval:
##  17.4552     Inf
## sample estimates:
## mean of x 
##  18.72469
```
We first input Rose's game scores, followed by mu or the population
mean. We also are only interested if Rose's mean score is greater than
the population mean, and not lesser than. Because of this, our t-test
can be one-tailed, which we specify by saying .

Using the typical hypothesis testing lingo (I promise not to use it a
lot), the null hypothesis is that Rose's mean game score is not
significantly greater than the population mean. The alternative is that
Rose's mean is significantly greater than the population mean. We set an
alpha or significance value (usually .05) which we'll compare the
p-value to. If the p-value is below the significance level, we reject
the null, but if it's not we fail to reject it. Although the p-value is
the go to for most people to determine significant effect, never use it
as a sole measure. Make sure to include things like confidence intervals
as a way to back up your claims, not just the p-value.

Now, looking at the results show that Rose's mean game score is
signicantly higher than the population mean. The 95% confidence interval
shows that the mean game score for Derrick Rose tends to be above 17.45.
The p-value is below .05, showing that the difference is significant at
the traditional .05 significance level.

Before we celebrate too much, there are some diagnostics we have to run.
Specifically, we have to test for normality in the distribution of
Rose's game scores. We can do this graphically, and with a more general
hypothesis test, the Shapiro-Wilk test.

First we'll show the graphical way. This is a quantile quantile (QQ)
plot, comparing sample and theoretical quantiles. Ideally, we want all
the points to line up diagonally on the quantile quantile line. We can
form this plot using the qqnorm command and make the line using the
qqline command:
```r
qqnorm(rose$GmSc)
qqline(rose$GmSc)
```

![](ttest_files/figure-markdown_strict/unnamed-chunk-4-1.png)

The points seem to follow the line for the most part, indicating that
the data is essentially normal. We can also use the Shapiro-Wilk test
like so:
```r
shapiro.test(rose$GmSc)

## 
##  Shapiro-Wilk normality test
## 
## data:  rose$GmSc
## W = 0.99037, p-value = 0.812
```
Because the p-value is not below .05, we can assume the data is
approximately normal. Knowing this, our t-test is valid!

### Two Sample T-Test ###


Now we'll go back to our example mentioned at the beginning, comparing
James and Rose's game scores. Let's first look at the distribution of
game scores in a box plot.
```r
rbind(rose, james) %>%
  ggplot(aes(x=Player, y=GmSc))+
  geom_jitter(alpha=.4, width = .2)+
  geom_boxplot(fill="skyblue", alpha=.6, outlier.colour = NA)
```
![](ttest_files/figure-markdown_strict/unnamed-chunk-6-1.png)

Based on the graph, it looks like James' distribution of game scores is
slightly higher than Rose's.

Before we run any tests on the data, let's run diagnostics on James'
data.
```r
qqnorm(james$GmSc)
qqline(james$GmSc)
```
![](ttest_files/figure-markdown_strict/unnamed-chunk-7-1.png)
```r
shapiro.test(james$GmSc)

## 
##  Shapiro-Wilk normality test
## 
## data:  james$GmSc
## W = 0.97822, p-value = 0.1954
```
Based on the QQ plot and the Shapiro-Wilk test, it appears as though
James' game score data is approximately normal.

Now this test comparing two independent samples is slightly different
than the previous one-sampled test. In a two-sample t-test, we also have
to check for equal variance between the samples. We can do this with the
var.test command in R:
```r
var.test(rose$GmSc, james$GmSc)

## 
##  F test to compare two variances
## 
## data:  rose$GmSc and james$GmSc
## F = 0.88567, num df = 80, denom df = 78, p-value = 0.5901
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.5676193 1.3801857
## sample estimates:
## ratio of variances 
##          0.8856696
```
The p-value is above .05 and the 95% confidence interval includes 1, so
we can assume that the variances are approximately equal. Since both
samples are normal and the variances are equal, we can run a two-sample
student's t-test:
```r
t.test(rose$GmSc, james$GmSc, var.equal = T)

## 
##  Two Sample t-test
## 
## data:  rose$GmSc and james$GmSc
## t = -2.6911, df = 158, p-value = 0.007888
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -5.2248125 -0.8017541
## sample estimates:
## mean of x mean of y 
##  18.72469  21.73797
```
Although we used the same t.test command, the inputs are slighty
different. We specify because variances are equal. We also didn't
specify an alternative, making this a two-sided test. We are interested
in any difference, not whether one mean is significantly greater or
lesser.

The 95% confidence interval in the difference between Rose and James'
means is -5.22 and -.80; because it does not include 0, and because the
p-value is below .05, we can say there is a significant difference
between James' game scores and Rose's game scores. James' mean value is
significantly higher than Rose's.

Although game scores are just one measure, it appears as though LeBron
was better in this category than Rose. Maybe there's some truth to the
rumor that people were just fed up with LeBron winning all the time, so
they voted for the next best thing.

### What if Assumptions aren't met? ###

There are alternative t-tests that can be used if the variance and
normality assumptions aren't met. If the two samples have unequal
variances, a Welch t-test can be used. We can simply change up the TRUE
command to false:
```r
t.test(rose$GmSc, james$GmSc, var.equal = F)

## 
##  Welch Two Sample t-test
## 
## data:  rose$GmSc and james$GmSc
## t = -2.6891, df = 156.85, p-value = 0.00794
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -5.2266254 -0.7999412
## sample estimates:
## mean of x mean of y 
##  18.72469  21.73797
```
If the samples aren't normally distributed, we should use a
Mann-Whitney-Wilcoxon test. This is a non-parametric method in which we
don't have to assume a normal distribution.
```r
wilcox.test(rose$GmSc, james$GmSc)

## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  rose$GmSc and james$GmSc
## W = 2490, p-value = 0.01553
## alternative hypothesis: true location shift is not equal to 0
```
The results are both the same to the student's t-test we ended up using,
but the numbers are slightly different. It's good practice to use the
appropriate test when necessary, despite the results being the same in
this example, so make sure to always check your diagnostics!
