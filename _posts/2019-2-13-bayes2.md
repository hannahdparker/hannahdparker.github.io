---
layout: post
title: "Bayesian Inference Pt. 2: Bayesian Inference"
date: 2019-02-13 00:00:00
excerpt_separator: <!--more-->
---

In the last post, we saw a basic overview of Bayes rule, but we didn't
see it at its full power. Using fixed numbers as priors are fine, but we
can expand our priors to entire distributions! In this post, we expand
on using Bayesian methods for inference and compare it to the
frequentist hypothesis testing we were all taught in school.

<!--more-->

The Frequentist Method
======================

A lot of the previous posts that focused on statistical applications
used frequentist philosophy. T-tests, for example; we want to see if
there is a difference in means for two different populations. We can't
measure the entire population, so we take samples from both of our
groups and compare their distributions. We come up with a normalized
test statistic, in this case the t-statistic, that represents the
difference between the two groups. We then compare it to a normalized
distribution and see whether the difference is a result of chance or
not.

In this methodology, we are just using sample data to make assumptions
about the population as a whole. Frequentist statistics consider this
parameter as a fixed value; in the case of a t-test, the difference
between the groups is an actual fixed number.

The Bayesion Method
===================

In the last post, we went over Bayes rule:
<a href="https://www.codecogs.com/eqnedit.php?latex=P(X|Y)&space;=&space;\frac{P(Y|X)P(X)}{P(Y)}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(X|Y)&space;=&space;\frac{P(Y|X)P(X)}{P(Y)}" title="P(X|Y) = \frac{P(Y|X)P(X)}{P(Y)}" /></a>. Let's play around with what <a href="https://www.codecogs.com/eqnedit.php?latex=X" target="_blank"><img src="https://latex.codecogs.com/gif.latex?X" title="X" /></a>
and *Y* represent; we'll replace <a href="https://www.codecogs.com/eqnedit.php?latex=X" target="_blank"><img src="https://latex.codecogs.com/gif.latex?X" title="X" /></a> with <a href="https://www.codecogs.com/eqnedit.php?latex=\theta" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\theta" title="\theta" /></a>, our prior beliefs, and
<a href="https://www.codecogs.com/eqnedit.php?latex=Y" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Y" title="Y" /></a> with <a href="https://www.codecogs.com/eqnedit.php?latex=data" target="_blank"><img src="https://latex.codecogs.com/gif.latex?data" title="data" /></a>. This makes our equation:

<a href="https://www.codecogs.com/eqnedit.php?latex=P(\theta&space;|data)&space;=&space;\frac{P(data|\theta&space;)P(\theta&space;)}{P(data)}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(\theta&space;|data)&space;=&space;\frac{P(data|\theta&space;)P(\theta&space;)}{P(data)}" title="P(\theta |data) = \frac{P(data|\theta )P(\theta )}{P(data)}" /></a>

So now, we're looking at finding the probability of our prior beliefs
given the data. Let's cover some new vocabulary terms to get us familiar
with the Bayesian lingo.

-   Prior: <a href="https://www.codecogs.com/eqnedit.php?latex=P(\theta)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(\theta)" title="P(\theta)" /></a>, this is our belief, or hypothesis, going into the
    model. Our prior can have a large or small impact on the model
    depending on whether we have strong or weak prior beliefs. I may
    have a very strong prior belief that Steph Curry is going to hit a
    three pointer.

-   Likelihood: *<a href="https://www.codecogs.com/eqnedit.php?latex=P(data&space;|&space;\theta)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(data&space;|&space;\theta)" title="P(data | \theta)" /></a>, this is the probability of seeing
    our data given our prior beliefs. If we had a strong belief that
    Steph Curry hits a three, this is the probability of seeing the data
    we have.

-   Posterior: <a href="https://www.codecogs.com/eqnedit.php?latex=P(&space;\theta&space;|&space;data)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(&space;\theta&space;|&space;data)" title="P( \theta | data)" /></a>, this is the probability of our
    hypothesis given the data.

Notice that <a href="https://www.codecogs.com/eqnedit.php?latex=P(data)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(data)" title="P(data)" /></a>, also known as the evidence, is not
impacted at all by our hypothesis. It is acting strictly as a
normalizing constant. Because of this, we could say
<a href="https://www.codecogs.com/eqnedit.php?latex=P(\theta&space;|data)&space;\propto&space;P(data|\theta&space;)P(\theta&space;)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(\theta&space;|data)&space;\propto&space;P(data|\theta&space;)P(\theta&space;)" title="P(\theta |data) \propto P(data|\theta )P(\theta )" /></a>. Removing the
denominator gives us a distribution that is proportional to the
posterior distribution. This way, we can still find the most likely
value in the posterior distribution without having to calculate
<a href="https://www.codecogs.com/eqnedit.php?latex=P(data)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(data)" title="P(data)" /></a>. Note that this would change up the underlying values
of the density distribution as they would no longer integrate to 1, but
just something to keep in mind!

Should a Shooter Stop Shooting?
===============================

Let's look at Steph Curry as an example. Specifically, we'll focus on
his Christmas day game against the Lakers, in which he went a pretty
poor 5 of 17 from the field. The Warriors lost that game pretty handily,
but if you were Steve Kerr, would you have told Curry to not take his
next shot? Maybe he should look for some other weapons, rather than
continue this sub-30% shooting night.

Let's think about this from a Bayesian perspective... What's the
probability of Curry hitting his next shot given that he is currently
shooting 5 of 17? Let's break this down by each part of the Bayesian
formula:

-   Posterior: P(Curry hits a shot|Curry shoots 5 of 17)
-   Prior: P(Curry hits a shot)
-   Evidence: P(Curry shoots 5 of 17)
-   Likelihood: P(Curry shoots 5 of 17|prior belief that Curry hits a
    shot)

In terms of our prior, we may have one set value we want to assign to
Curry hitting his next shot, but that doesn't take advantage of our
ability to let our hypothesis be random. Let's develop a distribution of
Curry's shooting performances from the season up to this point. First
we'll pull the data from
[basketballreference.com](https://www.basketball-reference.com/players/c/curryst01/gamelog/2019).

    library(rvest)
    library(tidyverse)

    curry<-
      read_html("https://www.basketball-reference.com/players/c/curryst01/gamelog/2019") %>%
      html_node('#pgl_basic') %>%
      html_table(fill = T) %>%
      .[!is.na(names(.))] %>%
      select(Date, FG, FGA) %>%
      filter(Date != "Date") %>% 
      filter(FG != "Inactive") %>% 
      mutate(Date = as.Date(Date), FG = as.numeric(FG), FGA = as.numeric(FGA))

Let's now plot out what that distribution looks like:

    curry %>%
      ggplot(aes(x = FG/FGA)) +
      geom_density(fill = "#FDB927")

![](2019-2-13-bayes2_files/figure-markdown_strict/unnamed-chunk-2-1.png)

Now we can fit a distribution to this past data, and use this
distribution as our prior. A good distribution we could use to model
Curry's prior shooting percentages is a beta distribution. This will
look a lot like a normal distribution in most cases, but it is bound
between 0 and 1, making it great to model distributions of
probabilities.

The beta distribution has two parameters: shape 1 and shape 2. We can
think of these two shapes in a more general sense as the number of
successes and failures of an experiment. The following plots a few
different beta distributions.

![](2019-2-13-bayes2_files/figure-markdown_strict/unnamed-chunk-3-1.png)

Notice how a *b**e**t**a*(1, 1) distribution is just a flat line; this
is known as a uniform prior because it has the same density for all
probabilities. Also see how increasing the number of trials creates a
distribution with a smaller width and higher peak. That's because we
have more trials to base our distribution on!

Now, why don't we incorporate all of Curry's previous shooting logs into
our prior distribution? This is a process known as empiracle Bayes,
because we are using hard data as our prior belief. We can fit a beta
distribution to Curry's past game logs using the `fitdistr()` function
in the `MASS` package.

    library(MASS)
    beta.param<- fitdistr(x = curry$FG/curry$FGA, densfun = dbeta, start = list(shape1 = 1, shape2 = 1))

    beta.param$estimate

    ##   shape1   shape2 
    ## 7.646829 8.011954

We started out with a uniform beta shape and R fit a more concrete one
for us.

Let's plot this fit beta shape to the actual distribution of game logs
and see how well it matches up.

    curry %>%
      ggplot(aes(x = FG/FGA)) +
      stat_function(geom = "bar", fun = function(x) dbeta(x, beta.param$estimate[1], beta.param$estimate[2]),
                    aes(fill = "#006BB6"), alpha = .7, col = "black") +
      geom_density(aes(fill = "#FDB927"), alpha = .4) +
      xlim(0, 1) +
      scale_fill_manual(name = "Fill", labels = c("Beta Fit", "Real Distribution"), 
                        values = c("#FDB927" = "#FDB927", "#006BB6" = "#006BB6")) +  
      theme(legend.position = "top") + 
      labs(y = "density")

![](2019-2-13-bayes2_files/figure-markdown_strict/unnamed-chunk-5-1.png)

It fits pretty well (or about as well as we could do with a set
distribution). We can use MCMC methods to fit distributions that might
not match up that well with set distributions, but we'll save that for a
future lesson.

Now, let's think about our likelihood. This likelihood distribution
allows us to identify the most likely hypothesis given a set of data.
Like with our prior, we can represent this in our equation with a
distribution. Instead of using past games to model the distribution like
we did with our prior, we'll instead use the data we are currently
seeing, the Christmas day game.

So we want to represent the probability of different made shots given
that the current game has Curry with 5 successes out of 17 attempts...
that sounds like the ideal set-up for a binomial distribution! The
binomial distribution has two parameters in R: the number of successes
and the probability of success. Let's plot the likelihood distribution
across Curry seeing any number of possible makes, given he took 17
shots.

    data_frame(makes = c(0:17), prob = dbinom(c(0:17), size = 17, prob = 5/17)) %>%
      ggplot(aes(x = makes, y = prob)) +
      geom_linerange(aes(ymin = 0, ymax = prob), col = "#006BB6", size = 1.7) + 
      geom_point(size = 4, pch = 21, fill = "#FDB927", col = "#006BB6") +
      labs(x = "Makes", y = "Probability")

![](2019-2-13-bayes2_files/figure-markdown_strict/unnamed-chunk-6-1.png)

We can see the likelihood spikes around 5 makes, which makes sense
because that is the data we saw. If all we went off of was this one
game, a hypothesis that Curry would make about 60% of his shots (10 out
of 17) would be extremely low. Luckily, we can update the likelihood
with our past knowledge of how Curry actually performs!

Calculating the Posterior
=========================

So, we have our likelihood and priors set up; this is all we need to
calculate a distribution that is proportional to the posterior.
Remember: *P*(*θ*|*d**a**t**a*)∝*P*(*d**a**t**a*|*θ*)*P*(*θ*). Our
evidence is just a constant and would not change up based on our
hypothesis, *t**h**e**t**a*.

Now, let's think of these distributions mathematically:

-   The PMF for a binomial distribution is:
    $\\binom{n}{k}p^k(1-p)^{(n-k)}$ where *n* is the number of trials,
    *k* is the number of successes, and *p* is the success probability
    for each trial.
-   The PDF for a beta distribution is:
    $\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}x^{\\alpha - 1}(1 - x)^{\\beta - 1}$
    where *α* and *β* are the two shape parameters representing
    successes and failures and *x* are the different probability values.

We can multiply these two distributions together to get the posterior
distribution; to make our lives easier, we can again remove constants
that will not change up based on different probabilities and get a
proportional answer. So that means we can remove $\\binom{n}{k}$ and
$\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}$
because those values will only change based on distribution parameters,
which we have already set.

That gives us:
*P*(*θ*|*d**a**t**a*)∝*p*<sup>*k*</sup>(1 − *p*)<sup>(*n* − *k*)</sup>*x*<sup>*α* − 1</sup>(1 − *x*)<sup>*β* − 1</sup>.
We can simplify this to
*p*<sup>*α* + *k* + 1</sup>(1 − *p*)<sup>*β* + *n* − *k* − 1</sup>. You
may notice that this looks a lot like the beta distribution, and that's
because it is! The beta distribution is a conjugate prior for a binomial
distribution, meaning that the posterior will also be a beta
distribution. We can also add back in the integration constant since
this is a beta distribution, which has to be
$\\frac{\\Gamma(n + \\alpha + \\beta)}{\\Gamma(\\alpha + k)\\Gamma(\\beta + n - k)}$,
making our full posterior beta distribution look like:
$\\frac{\\Gamma(n + \\alpha + \\beta)}{\\Gamma(\\alpha + k)\\Gamma(\\beta + n - k)}p^{\\alpha + k + 1}(1-p)^{\\beta + n - k - 1}$.

In the end, all we need to do is just add the additional successes and
failures we saw in the Christmas day game to the shape parameters of the
beta distribution:
`dbeta(x, 5 + beta.param$estimate[1], 12 + beta.param$estimate[2])`.

Let's plot the prior, the likelihood, and the posterior to see how our
prior hypothesis changed due to how Curry was playing in the Christmas
day game:

![](2019-2-13-bayes2_files/figure-markdown_strict/unnamed-chunk-7-1.png)

We can see visually that the range of possible probabilities for Curry
to make a shot has gone down. Let's see what the max probability value
has changed to:

    #prior probability
    qbeta(p = .5, shape1 = 7.64, shape2 = 8.01)

    ## [1] 0.4876628

    #posterior probability
    qbeta(p = .5, shape1 = 12.64, shape2 = 20.01)

    ## [1] 0.3848048

The probability of Curry making his next shot has decreased by around
10%. This is still higher, of course than we would assume based off of
how he's playing in the Christmas day game, where he was shooting 29%,
but it's still a big drop.

We can get a range of the values that cover a certain proportion of the
posterior distribution, called a credible interval. We can use this
similarly (although the meaning is slightly different) to a confidence
interval. Let's use qbeta to get a 95% credible interval for the
posterior distribution.

    #posterior 95% interval
    qbeta(p = c(.025, .975), shape1 = 12.64, shape2 = 20.01)

    ## [1] 0.2303314 0.5570436

The odds of Curry hitting his next shot in this game are pretty low...
I'm not saying I'd tell him to stop shooting, but maybe it's something
to consider!

We are starting to see how helpful Bayesian analysis can be! If we were
only judging Steph on his Christmas day game, we'd tell him to pass it
if they want to stand any chance against the Lakers. But, when we take
our prior knowledge of his ability into account, his odds improve
(although they still aren't great). Bayesian inference really lets us
perform analysis in a more relatable manner; we are constantly taking
past knowledge and beliefs into account when we make decisions.

A great article if you want to see another example of Bayesian inference
in the sports field can be found and David Robinson's Variance Explained
[blog](http://varianceexplained.org/r/empirical_bayes_baseball/).
